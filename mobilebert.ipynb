{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pyarrow 16.0.0\n",
      "Uninstalling pyarrow-16.0.0:\n",
      "  Successfully uninstalled pyarrow-16.0.0\n",
      "Found existing installation: datasets 2.19.0\n",
      "Uninstalling datasets-2.19.0:\n",
      "  Successfully uninstalled datasets-2.19.0\n",
      "Collecting pyarrow\n",
      "  Using cached pyarrow-16.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/mamba/lib/python3.11/site-packages (from pyarrow) (1.26.4)\n",
      "Using cached pyarrow-16.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-16.0.0\n",
      "Collecting datasets\n",
      "  Using cached datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /opt/mamba/lib/python3.11/site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/mamba/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/mamba/lib/python3.11/site-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/mamba/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/mamba/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/mamba/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/mamba/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/mamba/lib/python3.11/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /opt/mamba/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/mamba/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/mamba/lib/python3.11/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/mamba/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/mamba/lib/python3.11/site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in /opt/mamba/lib/python3.11/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/mamba/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/mamba/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/mamba/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/mamba/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/mamba/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/mamba/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/mamba/lib/python3.11/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/mamba/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/mamba/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/mamba/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-2.19.0-py3-none-any.whl (542 kB)\n",
      "Installing collected packages: datasets\n",
      "Successfully installed datasets-2.19.0\n",
      "Requirement already satisfied: torch in /opt/mamba/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers in /opt/mamba/lib/python3.11/site-packages (4.40.1)\n",
      "Requirement already satisfied: filelock in /opt/mamba/lib/python3.11/site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/mamba/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/mamba/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/mamba/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/mamba/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/mamba/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/mamba/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/mamba/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/mamba/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/mamba/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/mamba/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/mamba/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/mamba/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/mamba/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/mamba/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/mamba/lib/python3.11/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/mamba/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/mamba/lib/python3.11/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/mamba/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/mamba/lib/python3.11/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/mamba/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/mamba/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/mamba/lib/python3.11/site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: requests in /opt/mamba/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/mamba/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/mamba/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/mamba/lib/python3.11/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/mamba/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/mamba/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers[torch] in /opt/mamba/lib/python3.11/site-packages (4.40.1)\n",
      "Requirement already satisfied: filelock in /opt/mamba/lib/python3.11/site-packages (from transformers[torch]) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/mamba/lib/python3.11/site-packages (from transformers[torch]) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/mamba/lib/python3.11/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.11/site-packages (from transformers[torch]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/mamba/lib/python3.11/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/mamba/lib/python3.11/site-packages (from transformers[torch]) (2024.4.16)\n",
      "Requirement already satisfied: requests in /opt/mamba/lib/python3.11/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/mamba/lib/python3.11/site-packages (from transformers[torch]) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/mamba/lib/python3.11/site-packages (from transformers[torch]) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/mamba/lib/python3.11/site-packages (from transformers[torch]) (4.66.2)\n",
      "Requirement already satisfied: torch in /opt/mamba/lib/python3.11/site-packages (from transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/mamba/lib/python3.11/site-packages (from transformers[torch]) (0.29.3)\n",
      "Requirement already satisfied: psutil in /opt/mamba/lib/python3.11/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/mamba/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/mamba/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/mamba/lib/python3.11/site-packages (from torch->transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/mamba/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.11/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.11/site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.11/site-packages (from requests->transformers[torch]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.11/site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/mamba/lib/python3.11/site-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/mamba/lib/python3.11/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: accelerate in /opt/mamba/lib/python3.11/site-packages (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/mamba/lib/python3.11/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.11/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/mamba/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/mamba/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/mamba/lib/python3.11/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/mamba/lib/python3.11/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/mamba/lib/python3.11/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/mamba/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/mamba/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in /opt/mamba/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/mamba/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/mamba/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/mamba/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/mamba/lib/python3.11/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/mamba/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/mamba/lib/python3.11/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/mamba/lib/python3.11/site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/mamba/lib/python3.11/site-packages (from scikit-learn) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y pyarrow datasets\n",
    "!pip install --no-use-pep517 pyarrow\n",
    "!pip install datasets\n",
    "!pip install torch transformers\n",
    "!pip install transformers[torch]\n",
    "!pip install accelerate -U\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupérer les données d'un challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filesystem object\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['civel/diffusion/hackathon-minarm-2024/AIVSAI/hack_train.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lister les fichiers d'un challenge\n",
    "fs.ls(\"civel/diffusion/hackathon-minarm-2024/AIVSAI/hack_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Télécharger les données dans le service\n",
    "PATH_IN = 'civel/diffusion/hackathon-minarm-2024/AIVSAI/hack_train.csv'\n",
    "fs.download(PATH_IN, 'data/hack_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/hack_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Little disclaimer: this deals with US laws and...</td>\n",
       "      <td>1</td>\n",
       "      <td>cmv_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Read: Mentally Retarded Downs. See, we've got ...</td>\n",
       "      <td>1</td>\n",
       "      <td>cmv_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If any of you frequent rbadhistory, there is a...</td>\n",
       "      <td>1</td>\n",
       "      <td>cmv_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I believe in a flat tax system, where everyone...</td>\n",
       "      <td>1</td>\n",
       "      <td>cmv_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edit: Ok guy's, my views have been changed on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>cmv_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56814</th>\n",
       "      <td>We consider the recovery of a source term f (x...</td>\n",
       "      <td>1</td>\n",
       "      <td>sci_gen_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56815</th>\n",
       "      <td>Self-supervised learning (SlfSL), aiming at le...</td>\n",
       "      <td>1</td>\n",
       "      <td>sci_gen_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56816</th>\n",
       "      <td>Recurrent neural networks (RNNs) have achieved...</td>\n",
       "      <td>1</td>\n",
       "      <td>sci_gen_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56817</th>\n",
       "      <td>Deep reinforcement learning (DRL) is a booming...</td>\n",
       "      <td>1</td>\n",
       "      <td>sci_gen_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56818</th>\n",
       "      <td>As part of Smart Cities initiatives, national,...</td>\n",
       "      <td>1</td>\n",
       "      <td>sci_gen_human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56819 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label            src\n",
       "0      Little disclaimer: this deals with US laws and...      1      cmv_human\n",
       "1      Read: Mentally Retarded Downs. See, we've got ...      1      cmv_human\n",
       "2      If any of you frequent rbadhistory, there is a...      1      cmv_human\n",
       "3      I believe in a flat tax system, where everyone...      1      cmv_human\n",
       "4      Edit: Ok guy's, my views have been changed on ...      1      cmv_human\n",
       "...                                                  ...    ...            ...\n",
       "56814  We consider the recovery of a source term f (x...      1  sci_gen_human\n",
       "56815  Self-supervised learning (SlfSL), aiming at le...      1  sci_gen_human\n",
       "56816  Recurrent neural networks (RNNs) have achieved...      1  sci_gen_human\n",
       "56817  Deep reinforcement learning (DRL) is a booming...      1  sci_gen_human\n",
       "56818  As part of Smart Cities initiatives, national,...      1  sci_gen_human\n",
       "\n",
       "[56819 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'MobileBertTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37eb3bf19fb46449f4fe45f9e40a8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['texts', 'labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 2\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from transformers import MobileBertTokenizer\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = MobileBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Create a Hugging Face Dataset from the data (if not already in one)\n",
    "data_dict = {\n",
    "    \"texts\": df['text'],\n",
    "    \"labels\": df['label']\n",
    "}\n",
    "hf_dataset = Dataset.from_dict(data_dict)\n",
    "\n",
    "# Define the preprocessing function to tokenize the data\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    tokenized_inputs = tokenizer(examples['texts'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    \n",
    "    # Prepare the dictionary correctly.\n",
    "    return {\n",
    "        'input_ids': tokenized_inputs['input_ids'], \n",
    "        'attention_mask': tokenized_inputs['attention_mask'], \n",
    "        'labels': examples['labels']\n",
    "    }\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "tokenized_datasets = hf_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Display the first few processed entries to verify\n",
    "print(tokenized_datasets.select(range(2)))  # Select the first two entries for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 24 16:04:48 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA H100 PCIe               Off | 00000000:B5:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              53W / 350W |      4MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type mobilebert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b76372b9bb145d7ac57de21cf53279c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.embedding_transformation.bias', 'embeddings.embedding_transformation.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.bottleneck.attention.LayerNorm.bias', 'encoder.layer.0.bottleneck.attention.LayerNorm.weight', 'encoder.layer.0.bottleneck.attention.dense.bias', 'encoder.layer.0.bottleneck.attention.dense.weight', 'encoder.layer.0.bottleneck.input.LayerNorm.bias', 'encoder.layer.0.bottleneck.input.LayerNorm.weight', 'encoder.layer.0.bottleneck.input.dense.bias', 'encoder.layer.0.bottleneck.input.dense.weight', 'encoder.layer.0.ffn.0.intermediate.dense.bias', 'encoder.layer.0.ffn.0.intermediate.dense.weight', 'encoder.layer.0.ffn.0.output.LayerNorm.bias', 'encoder.layer.0.ffn.0.output.LayerNorm.weight', 'encoder.layer.0.ffn.0.output.dense.bias', 'encoder.layer.0.ffn.0.output.dense.weight', 'encoder.layer.0.ffn.1.intermediate.dense.bias', 'encoder.layer.0.ffn.1.intermediate.dense.weight', 'encoder.layer.0.ffn.1.output.LayerNorm.bias', 'encoder.layer.0.ffn.1.output.LayerNorm.weight', 'encoder.layer.0.ffn.1.output.dense.bias', 'encoder.layer.0.ffn.1.output.dense.weight', 'encoder.layer.0.ffn.2.intermediate.dense.bias', 'encoder.layer.0.ffn.2.intermediate.dense.weight', 'encoder.layer.0.ffn.2.output.LayerNorm.bias', 'encoder.layer.0.ffn.2.output.LayerNorm.weight', 'encoder.layer.0.ffn.2.output.dense.bias', 'encoder.layer.0.ffn.2.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.bottleneck.LayerNorm.bias', 'encoder.layer.0.output.bottleneck.LayerNorm.weight', 'encoder.layer.0.output.bottleneck.dense.bias', 'encoder.layer.0.output.bottleneck.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.bottleneck.attention.LayerNorm.bias', 'encoder.layer.1.bottleneck.attention.LayerNorm.weight', 'encoder.layer.1.bottleneck.attention.dense.bias', 'encoder.layer.1.bottleneck.attention.dense.weight', 'encoder.layer.1.bottleneck.input.LayerNorm.bias', 'encoder.layer.1.bottleneck.input.LayerNorm.weight', 'encoder.layer.1.bottleneck.input.dense.bias', 'encoder.layer.1.bottleneck.input.dense.weight', 'encoder.layer.1.ffn.0.intermediate.dense.bias', 'encoder.layer.1.ffn.0.intermediate.dense.weight', 'encoder.layer.1.ffn.0.output.LayerNorm.bias', 'encoder.layer.1.ffn.0.output.LayerNorm.weight', 'encoder.layer.1.ffn.0.output.dense.bias', 'encoder.layer.1.ffn.0.output.dense.weight', 'encoder.layer.1.ffn.1.intermediate.dense.bias', 'encoder.layer.1.ffn.1.intermediate.dense.weight', 'encoder.layer.1.ffn.1.output.LayerNorm.bias', 'encoder.layer.1.ffn.1.output.LayerNorm.weight', 'encoder.layer.1.ffn.1.output.dense.bias', 'encoder.layer.1.ffn.1.output.dense.weight', 'encoder.layer.1.ffn.2.intermediate.dense.bias', 'encoder.layer.1.ffn.2.intermediate.dense.weight', 'encoder.layer.1.ffn.2.output.LayerNorm.bias', 'encoder.layer.1.ffn.2.output.LayerNorm.weight', 'encoder.layer.1.ffn.2.output.dense.bias', 'encoder.layer.1.ffn.2.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.bottleneck.LayerNorm.bias', 'encoder.layer.1.output.bottleneck.LayerNorm.weight', 'encoder.layer.1.output.bottleneck.dense.bias', 'encoder.layer.1.output.bottleneck.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.bottleneck.attention.LayerNorm.bias', 'encoder.layer.10.bottleneck.attention.LayerNorm.weight', 'encoder.layer.10.bottleneck.attention.dense.bias', 'encoder.layer.10.bottleneck.attention.dense.weight', 'encoder.layer.10.bottleneck.input.LayerNorm.bias', 'encoder.layer.10.bottleneck.input.LayerNorm.weight', 'encoder.layer.10.bottleneck.input.dense.bias', 'encoder.layer.10.bottleneck.input.dense.weight', 'encoder.layer.10.ffn.0.intermediate.dense.bias', 'encoder.layer.10.ffn.0.intermediate.dense.weight', 'encoder.layer.10.ffn.0.output.LayerNorm.bias', 'encoder.layer.10.ffn.0.output.LayerNorm.weight', 'encoder.layer.10.ffn.0.output.dense.bias', 'encoder.layer.10.ffn.0.output.dense.weight', 'encoder.layer.10.ffn.1.intermediate.dense.bias', 'encoder.layer.10.ffn.1.intermediate.dense.weight', 'encoder.layer.10.ffn.1.output.LayerNorm.bias', 'encoder.layer.10.ffn.1.output.LayerNorm.weight', 'encoder.layer.10.ffn.1.output.dense.bias', 'encoder.layer.10.ffn.1.output.dense.weight', 'encoder.layer.10.ffn.2.intermediate.dense.bias', 'encoder.layer.10.ffn.2.intermediate.dense.weight', 'encoder.layer.10.ffn.2.output.LayerNorm.bias', 'encoder.layer.10.ffn.2.output.LayerNorm.weight', 'encoder.layer.10.ffn.2.output.dense.bias', 'encoder.layer.10.ffn.2.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.bottleneck.LayerNorm.bias', 'encoder.layer.10.output.bottleneck.LayerNorm.weight', 'encoder.layer.10.output.bottleneck.dense.bias', 'encoder.layer.10.output.bottleneck.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.bottleneck.attention.LayerNorm.bias', 'encoder.layer.11.bottleneck.attention.LayerNorm.weight', 'encoder.layer.11.bottleneck.attention.dense.bias', 'encoder.layer.11.bottleneck.attention.dense.weight', 'encoder.layer.11.bottleneck.input.LayerNorm.bias', 'encoder.layer.11.bottleneck.input.LayerNorm.weight', 'encoder.layer.11.bottleneck.input.dense.bias', 'encoder.layer.11.bottleneck.input.dense.weight', 'encoder.layer.11.ffn.0.intermediate.dense.bias', 'encoder.layer.11.ffn.0.intermediate.dense.weight', 'encoder.layer.11.ffn.0.output.LayerNorm.bias', 'encoder.layer.11.ffn.0.output.LayerNorm.weight', 'encoder.layer.11.ffn.0.output.dense.bias', 'encoder.layer.11.ffn.0.output.dense.weight', 'encoder.layer.11.ffn.1.intermediate.dense.bias', 'encoder.layer.11.ffn.1.intermediate.dense.weight', 'encoder.layer.11.ffn.1.output.LayerNorm.bias', 'encoder.layer.11.ffn.1.output.LayerNorm.weight', 'encoder.layer.11.ffn.1.output.dense.bias', 'encoder.layer.11.ffn.1.output.dense.weight', 'encoder.layer.11.ffn.2.intermediate.dense.bias', 'encoder.layer.11.ffn.2.intermediate.dense.weight', 'encoder.layer.11.ffn.2.output.LayerNorm.bias', 'encoder.layer.11.ffn.2.output.LayerNorm.weight', 'encoder.layer.11.ffn.2.output.dense.bias', 'encoder.layer.11.ffn.2.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.bottleneck.LayerNorm.bias', 'encoder.layer.11.output.bottleneck.LayerNorm.weight', 'encoder.layer.11.output.bottleneck.dense.bias', 'encoder.layer.11.output.bottleneck.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.12.bottleneck.attention.LayerNorm.bias', 'encoder.layer.12.bottleneck.attention.LayerNorm.weight', 'encoder.layer.12.bottleneck.attention.dense.bias', 'encoder.layer.12.bottleneck.attention.dense.weight', 'encoder.layer.12.bottleneck.input.LayerNorm.bias', 'encoder.layer.12.bottleneck.input.LayerNorm.weight', 'encoder.layer.12.bottleneck.input.dense.bias', 'encoder.layer.12.bottleneck.input.dense.weight', 'encoder.layer.12.ffn.0.intermediate.dense.bias', 'encoder.layer.12.ffn.0.intermediate.dense.weight', 'encoder.layer.12.ffn.0.output.LayerNorm.bias', 'encoder.layer.12.ffn.0.output.LayerNorm.weight', 'encoder.layer.12.ffn.0.output.dense.bias', 'encoder.layer.12.ffn.0.output.dense.weight', 'encoder.layer.12.ffn.1.intermediate.dense.bias', 'encoder.layer.12.ffn.1.intermediate.dense.weight', 'encoder.layer.12.ffn.1.output.LayerNorm.bias', 'encoder.layer.12.ffn.1.output.LayerNorm.weight', 'encoder.layer.12.ffn.1.output.dense.bias', 'encoder.layer.12.ffn.1.output.dense.weight', 'encoder.layer.12.ffn.2.intermediate.dense.bias', 'encoder.layer.12.ffn.2.intermediate.dense.weight', 'encoder.layer.12.ffn.2.output.LayerNorm.bias', 'encoder.layer.12.ffn.2.output.LayerNorm.weight', 'encoder.layer.12.ffn.2.output.dense.bias', 'encoder.layer.12.ffn.2.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.12.output.bottleneck.LayerNorm.bias', 'encoder.layer.12.output.bottleneck.LayerNorm.weight', 'encoder.layer.12.output.bottleneck.dense.bias', 'encoder.layer.12.output.bottleneck.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.13.bottleneck.attention.LayerNorm.bias', 'encoder.layer.13.bottleneck.attention.LayerNorm.weight', 'encoder.layer.13.bottleneck.attention.dense.bias', 'encoder.layer.13.bottleneck.attention.dense.weight', 'encoder.layer.13.bottleneck.input.LayerNorm.bias', 'encoder.layer.13.bottleneck.input.LayerNorm.weight', 'encoder.layer.13.bottleneck.input.dense.bias', 'encoder.layer.13.bottleneck.input.dense.weight', 'encoder.layer.13.ffn.0.intermediate.dense.bias', 'encoder.layer.13.ffn.0.intermediate.dense.weight', 'encoder.layer.13.ffn.0.output.LayerNorm.bias', 'encoder.layer.13.ffn.0.output.LayerNorm.weight', 'encoder.layer.13.ffn.0.output.dense.bias', 'encoder.layer.13.ffn.0.output.dense.weight', 'encoder.layer.13.ffn.1.intermediate.dense.bias', 'encoder.layer.13.ffn.1.intermediate.dense.weight', 'encoder.layer.13.ffn.1.output.LayerNorm.bias', 'encoder.layer.13.ffn.1.output.LayerNorm.weight', 'encoder.layer.13.ffn.1.output.dense.bias', 'encoder.layer.13.ffn.1.output.dense.weight', 'encoder.layer.13.ffn.2.intermediate.dense.bias', 'encoder.layer.13.ffn.2.intermediate.dense.weight', 'encoder.layer.13.ffn.2.output.LayerNorm.bias', 'encoder.layer.13.ffn.2.output.LayerNorm.weight', 'encoder.layer.13.ffn.2.output.dense.bias', 'encoder.layer.13.ffn.2.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.13.output.bottleneck.LayerNorm.bias', 'encoder.layer.13.output.bottleneck.LayerNorm.weight', 'encoder.layer.13.output.bottleneck.dense.bias', 'encoder.layer.13.output.bottleneck.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.14.bottleneck.attention.LayerNorm.bias', 'encoder.layer.14.bottleneck.attention.LayerNorm.weight', 'encoder.layer.14.bottleneck.attention.dense.bias', 'encoder.layer.14.bottleneck.attention.dense.weight', 'encoder.layer.14.bottleneck.input.LayerNorm.bias', 'encoder.layer.14.bottleneck.input.LayerNorm.weight', 'encoder.layer.14.bottleneck.input.dense.bias', 'encoder.layer.14.bottleneck.input.dense.weight', 'encoder.layer.14.ffn.0.intermediate.dense.bias', 'encoder.layer.14.ffn.0.intermediate.dense.weight', 'encoder.layer.14.ffn.0.output.LayerNorm.bias', 'encoder.layer.14.ffn.0.output.LayerNorm.weight', 'encoder.layer.14.ffn.0.output.dense.bias', 'encoder.layer.14.ffn.0.output.dense.weight', 'encoder.layer.14.ffn.1.intermediate.dense.bias', 'encoder.layer.14.ffn.1.intermediate.dense.weight', 'encoder.layer.14.ffn.1.output.LayerNorm.bias', 'encoder.layer.14.ffn.1.output.LayerNorm.weight', 'encoder.layer.14.ffn.1.output.dense.bias', 'encoder.layer.14.ffn.1.output.dense.weight', 'encoder.layer.14.ffn.2.intermediate.dense.bias', 'encoder.layer.14.ffn.2.intermediate.dense.weight', 'encoder.layer.14.ffn.2.output.LayerNorm.bias', 'encoder.layer.14.ffn.2.output.LayerNorm.weight', 'encoder.layer.14.ffn.2.output.dense.bias', 'encoder.layer.14.ffn.2.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.14.output.bottleneck.LayerNorm.bias', 'encoder.layer.14.output.bottleneck.LayerNorm.weight', 'encoder.layer.14.output.bottleneck.dense.bias', 'encoder.layer.14.output.bottleneck.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.15.bottleneck.attention.LayerNorm.bias', 'encoder.layer.15.bottleneck.attention.LayerNorm.weight', 'encoder.layer.15.bottleneck.attention.dense.bias', 'encoder.layer.15.bottleneck.attention.dense.weight', 'encoder.layer.15.bottleneck.input.LayerNorm.bias', 'encoder.layer.15.bottleneck.input.LayerNorm.weight', 'encoder.layer.15.bottleneck.input.dense.bias', 'encoder.layer.15.bottleneck.input.dense.weight', 'encoder.layer.15.ffn.0.intermediate.dense.bias', 'encoder.layer.15.ffn.0.intermediate.dense.weight', 'encoder.layer.15.ffn.0.output.LayerNorm.bias', 'encoder.layer.15.ffn.0.output.LayerNorm.weight', 'encoder.layer.15.ffn.0.output.dense.bias', 'encoder.layer.15.ffn.0.output.dense.weight', 'encoder.layer.15.ffn.1.intermediate.dense.bias', 'encoder.layer.15.ffn.1.intermediate.dense.weight', 'encoder.layer.15.ffn.1.output.LayerNorm.bias', 'encoder.layer.15.ffn.1.output.LayerNorm.weight', 'encoder.layer.15.ffn.1.output.dense.bias', 'encoder.layer.15.ffn.1.output.dense.weight', 'encoder.layer.15.ffn.2.intermediate.dense.bias', 'encoder.layer.15.ffn.2.intermediate.dense.weight', 'encoder.layer.15.ffn.2.output.LayerNorm.bias', 'encoder.layer.15.ffn.2.output.LayerNorm.weight', 'encoder.layer.15.ffn.2.output.dense.bias', 'encoder.layer.15.ffn.2.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.15.output.bottleneck.LayerNorm.bias', 'encoder.layer.15.output.bottleneck.LayerNorm.weight', 'encoder.layer.15.output.bottleneck.dense.bias', 'encoder.layer.15.output.bottleneck.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.16.bottleneck.attention.LayerNorm.bias', 'encoder.layer.16.bottleneck.attention.LayerNorm.weight', 'encoder.layer.16.bottleneck.attention.dense.bias', 'encoder.layer.16.bottleneck.attention.dense.weight', 'encoder.layer.16.bottleneck.input.LayerNorm.bias', 'encoder.layer.16.bottleneck.input.LayerNorm.weight', 'encoder.layer.16.bottleneck.input.dense.bias', 'encoder.layer.16.bottleneck.input.dense.weight', 'encoder.layer.16.ffn.0.intermediate.dense.bias', 'encoder.layer.16.ffn.0.intermediate.dense.weight', 'encoder.layer.16.ffn.0.output.LayerNorm.bias', 'encoder.layer.16.ffn.0.output.LayerNorm.weight', 'encoder.layer.16.ffn.0.output.dense.bias', 'encoder.layer.16.ffn.0.output.dense.weight', 'encoder.layer.16.ffn.1.intermediate.dense.bias', 'encoder.layer.16.ffn.1.intermediate.dense.weight', 'encoder.layer.16.ffn.1.output.LayerNorm.bias', 'encoder.layer.16.ffn.1.output.LayerNorm.weight', 'encoder.layer.16.ffn.1.output.dense.bias', 'encoder.layer.16.ffn.1.output.dense.weight', 'encoder.layer.16.ffn.2.intermediate.dense.bias', 'encoder.layer.16.ffn.2.intermediate.dense.weight', 'encoder.layer.16.ffn.2.output.LayerNorm.bias', 'encoder.layer.16.ffn.2.output.LayerNorm.weight', 'encoder.layer.16.ffn.2.output.dense.bias', 'encoder.layer.16.ffn.2.output.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.16.output.bottleneck.LayerNorm.bias', 'encoder.layer.16.output.bottleneck.LayerNorm.weight', 'encoder.layer.16.output.bottleneck.dense.bias', 'encoder.layer.16.output.bottleneck.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.17.bottleneck.attention.LayerNorm.bias', 'encoder.layer.17.bottleneck.attention.LayerNorm.weight', 'encoder.layer.17.bottleneck.attention.dense.bias', 'encoder.layer.17.bottleneck.attention.dense.weight', 'encoder.layer.17.bottleneck.input.LayerNorm.bias', 'encoder.layer.17.bottleneck.input.LayerNorm.weight', 'encoder.layer.17.bottleneck.input.dense.bias', 'encoder.layer.17.bottleneck.input.dense.weight', 'encoder.layer.17.ffn.0.intermediate.dense.bias', 'encoder.layer.17.ffn.0.intermediate.dense.weight', 'encoder.layer.17.ffn.0.output.LayerNorm.bias', 'encoder.layer.17.ffn.0.output.LayerNorm.weight', 'encoder.layer.17.ffn.0.output.dense.bias', 'encoder.layer.17.ffn.0.output.dense.weight', 'encoder.layer.17.ffn.1.intermediate.dense.bias', 'encoder.layer.17.ffn.1.intermediate.dense.weight', 'encoder.layer.17.ffn.1.output.LayerNorm.bias', 'encoder.layer.17.ffn.1.output.LayerNorm.weight', 'encoder.layer.17.ffn.1.output.dense.bias', 'encoder.layer.17.ffn.1.output.dense.weight', 'encoder.layer.17.ffn.2.intermediate.dense.bias', 'encoder.layer.17.ffn.2.intermediate.dense.weight', 'encoder.layer.17.ffn.2.output.LayerNorm.bias', 'encoder.layer.17.ffn.2.output.LayerNorm.weight', 'encoder.layer.17.ffn.2.output.dense.bias', 'encoder.layer.17.ffn.2.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.17.output.bottleneck.LayerNorm.bias', 'encoder.layer.17.output.bottleneck.LayerNorm.weight', 'encoder.layer.17.output.bottleneck.dense.bias', 'encoder.layer.17.output.bottleneck.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.18.bottleneck.attention.LayerNorm.bias', 'encoder.layer.18.bottleneck.attention.LayerNorm.weight', 'encoder.layer.18.bottleneck.attention.dense.bias', 'encoder.layer.18.bottleneck.attention.dense.weight', 'encoder.layer.18.bottleneck.input.LayerNorm.bias', 'encoder.layer.18.bottleneck.input.LayerNorm.weight', 'encoder.layer.18.bottleneck.input.dense.bias', 'encoder.layer.18.bottleneck.input.dense.weight', 'encoder.layer.18.ffn.0.intermediate.dense.bias', 'encoder.layer.18.ffn.0.intermediate.dense.weight', 'encoder.layer.18.ffn.0.output.LayerNorm.bias', 'encoder.layer.18.ffn.0.output.LayerNorm.weight', 'encoder.layer.18.ffn.0.output.dense.bias', 'encoder.layer.18.ffn.0.output.dense.weight', 'encoder.layer.18.ffn.1.intermediate.dense.bias', 'encoder.layer.18.ffn.1.intermediate.dense.weight', 'encoder.layer.18.ffn.1.output.LayerNorm.bias', 'encoder.layer.18.ffn.1.output.LayerNorm.weight', 'encoder.layer.18.ffn.1.output.dense.bias', 'encoder.layer.18.ffn.1.output.dense.weight', 'encoder.layer.18.ffn.2.intermediate.dense.bias', 'encoder.layer.18.ffn.2.intermediate.dense.weight', 'encoder.layer.18.ffn.2.output.LayerNorm.bias', 'encoder.layer.18.ffn.2.output.LayerNorm.weight', 'encoder.layer.18.ffn.2.output.dense.bias', 'encoder.layer.18.ffn.2.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.18.output.bottleneck.LayerNorm.bias', 'encoder.layer.18.output.bottleneck.LayerNorm.weight', 'encoder.layer.18.output.bottleneck.dense.bias', 'encoder.layer.18.output.bottleneck.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.19.bottleneck.attention.LayerNorm.bias', 'encoder.layer.19.bottleneck.attention.LayerNorm.weight', 'encoder.layer.19.bottleneck.attention.dense.bias', 'encoder.layer.19.bottleneck.attention.dense.weight', 'encoder.layer.19.bottleneck.input.LayerNorm.bias', 'encoder.layer.19.bottleneck.input.LayerNorm.weight', 'encoder.layer.19.bottleneck.input.dense.bias', 'encoder.layer.19.bottleneck.input.dense.weight', 'encoder.layer.19.ffn.0.intermediate.dense.bias', 'encoder.layer.19.ffn.0.intermediate.dense.weight', 'encoder.layer.19.ffn.0.output.LayerNorm.bias', 'encoder.layer.19.ffn.0.output.LayerNorm.weight', 'encoder.layer.19.ffn.0.output.dense.bias', 'encoder.layer.19.ffn.0.output.dense.weight', 'encoder.layer.19.ffn.1.intermediate.dense.bias', 'encoder.layer.19.ffn.1.intermediate.dense.weight', 'encoder.layer.19.ffn.1.output.LayerNorm.bias', 'encoder.layer.19.ffn.1.output.LayerNorm.weight', 'encoder.layer.19.ffn.1.output.dense.bias', 'encoder.layer.19.ffn.1.output.dense.weight', 'encoder.layer.19.ffn.2.intermediate.dense.bias', 'encoder.layer.19.ffn.2.intermediate.dense.weight', 'encoder.layer.19.ffn.2.output.LayerNorm.bias', 'encoder.layer.19.ffn.2.output.LayerNorm.weight', 'encoder.layer.19.ffn.2.output.dense.bias', 'encoder.layer.19.ffn.2.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.output.bottleneck.LayerNorm.bias', 'encoder.layer.19.output.bottleneck.LayerNorm.weight', 'encoder.layer.19.output.bottleneck.dense.bias', 'encoder.layer.19.output.bottleneck.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.bottleneck.attention.LayerNorm.bias', 'encoder.layer.2.bottleneck.attention.LayerNorm.weight', 'encoder.layer.2.bottleneck.attention.dense.bias', 'encoder.layer.2.bottleneck.attention.dense.weight', 'encoder.layer.2.bottleneck.input.LayerNorm.bias', 'encoder.layer.2.bottleneck.input.LayerNorm.weight', 'encoder.layer.2.bottleneck.input.dense.bias', 'encoder.layer.2.bottleneck.input.dense.weight', 'encoder.layer.2.ffn.0.intermediate.dense.bias', 'encoder.layer.2.ffn.0.intermediate.dense.weight', 'encoder.layer.2.ffn.0.output.LayerNorm.bias', 'encoder.layer.2.ffn.0.output.LayerNorm.weight', 'encoder.layer.2.ffn.0.output.dense.bias', 'encoder.layer.2.ffn.0.output.dense.weight', 'encoder.layer.2.ffn.1.intermediate.dense.bias', 'encoder.layer.2.ffn.1.intermediate.dense.weight', 'encoder.layer.2.ffn.1.output.LayerNorm.bias', 'encoder.layer.2.ffn.1.output.LayerNorm.weight', 'encoder.layer.2.ffn.1.output.dense.bias', 'encoder.layer.2.ffn.1.output.dense.weight', 'encoder.layer.2.ffn.2.intermediate.dense.bias', 'encoder.layer.2.ffn.2.intermediate.dense.weight', 'encoder.layer.2.ffn.2.output.LayerNorm.bias', 'encoder.layer.2.ffn.2.output.LayerNorm.weight', 'encoder.layer.2.ffn.2.output.dense.bias', 'encoder.layer.2.ffn.2.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.bottleneck.LayerNorm.bias', 'encoder.layer.2.output.bottleneck.LayerNorm.weight', 'encoder.layer.2.output.bottleneck.dense.bias', 'encoder.layer.2.output.bottleneck.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.20.bottleneck.attention.LayerNorm.bias', 'encoder.layer.20.bottleneck.attention.LayerNorm.weight', 'encoder.layer.20.bottleneck.attention.dense.bias', 'encoder.layer.20.bottleneck.attention.dense.weight', 'encoder.layer.20.bottleneck.input.LayerNorm.bias', 'encoder.layer.20.bottleneck.input.LayerNorm.weight', 'encoder.layer.20.bottleneck.input.dense.bias', 'encoder.layer.20.bottleneck.input.dense.weight', 'encoder.layer.20.ffn.0.intermediate.dense.bias', 'encoder.layer.20.ffn.0.intermediate.dense.weight', 'encoder.layer.20.ffn.0.output.LayerNorm.bias', 'encoder.layer.20.ffn.0.output.LayerNorm.weight', 'encoder.layer.20.ffn.0.output.dense.bias', 'encoder.layer.20.ffn.0.output.dense.weight', 'encoder.layer.20.ffn.1.intermediate.dense.bias', 'encoder.layer.20.ffn.1.intermediate.dense.weight', 'encoder.layer.20.ffn.1.output.LayerNorm.bias', 'encoder.layer.20.ffn.1.output.LayerNorm.weight', 'encoder.layer.20.ffn.1.output.dense.bias', 'encoder.layer.20.ffn.1.output.dense.weight', 'encoder.layer.20.ffn.2.intermediate.dense.bias', 'encoder.layer.20.ffn.2.intermediate.dense.weight', 'encoder.layer.20.ffn.2.output.LayerNorm.bias', 'encoder.layer.20.ffn.2.output.LayerNorm.weight', 'encoder.layer.20.ffn.2.output.dense.bias', 'encoder.layer.20.ffn.2.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.20.output.bottleneck.LayerNorm.bias', 'encoder.layer.20.output.bottleneck.LayerNorm.weight', 'encoder.layer.20.output.bottleneck.dense.bias', 'encoder.layer.20.output.bottleneck.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.21.bottleneck.attention.LayerNorm.bias', 'encoder.layer.21.bottleneck.attention.LayerNorm.weight', 'encoder.layer.21.bottleneck.attention.dense.bias', 'encoder.layer.21.bottleneck.attention.dense.weight', 'encoder.layer.21.bottleneck.input.LayerNorm.bias', 'encoder.layer.21.bottleneck.input.LayerNorm.weight', 'encoder.layer.21.bottleneck.input.dense.bias', 'encoder.layer.21.bottleneck.input.dense.weight', 'encoder.layer.21.ffn.0.intermediate.dense.bias', 'encoder.layer.21.ffn.0.intermediate.dense.weight', 'encoder.layer.21.ffn.0.output.LayerNorm.bias', 'encoder.layer.21.ffn.0.output.LayerNorm.weight', 'encoder.layer.21.ffn.0.output.dense.bias', 'encoder.layer.21.ffn.0.output.dense.weight', 'encoder.layer.21.ffn.1.intermediate.dense.bias', 'encoder.layer.21.ffn.1.intermediate.dense.weight', 'encoder.layer.21.ffn.1.output.LayerNorm.bias', 'encoder.layer.21.ffn.1.output.LayerNorm.weight', 'encoder.layer.21.ffn.1.output.dense.bias', 'encoder.layer.21.ffn.1.output.dense.weight', 'encoder.layer.21.ffn.2.intermediate.dense.bias', 'encoder.layer.21.ffn.2.intermediate.dense.weight', 'encoder.layer.21.ffn.2.output.LayerNorm.bias', 'encoder.layer.21.ffn.2.output.LayerNorm.weight', 'encoder.layer.21.ffn.2.output.dense.bias', 'encoder.layer.21.ffn.2.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.21.output.bottleneck.LayerNorm.bias', 'encoder.layer.21.output.bottleneck.LayerNorm.weight', 'encoder.layer.21.output.bottleneck.dense.bias', 'encoder.layer.21.output.bottleneck.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.22.bottleneck.attention.LayerNorm.bias', 'encoder.layer.22.bottleneck.attention.LayerNorm.weight', 'encoder.layer.22.bottleneck.attention.dense.bias', 'encoder.layer.22.bottleneck.attention.dense.weight', 'encoder.layer.22.bottleneck.input.LayerNorm.bias', 'encoder.layer.22.bottleneck.input.LayerNorm.weight', 'encoder.layer.22.bottleneck.input.dense.bias', 'encoder.layer.22.bottleneck.input.dense.weight', 'encoder.layer.22.ffn.0.intermediate.dense.bias', 'encoder.layer.22.ffn.0.intermediate.dense.weight', 'encoder.layer.22.ffn.0.output.LayerNorm.bias', 'encoder.layer.22.ffn.0.output.LayerNorm.weight', 'encoder.layer.22.ffn.0.output.dense.bias', 'encoder.layer.22.ffn.0.output.dense.weight', 'encoder.layer.22.ffn.1.intermediate.dense.bias', 'encoder.layer.22.ffn.1.intermediate.dense.weight', 'encoder.layer.22.ffn.1.output.LayerNorm.bias', 'encoder.layer.22.ffn.1.output.LayerNorm.weight', 'encoder.layer.22.ffn.1.output.dense.bias', 'encoder.layer.22.ffn.1.output.dense.weight', 'encoder.layer.22.ffn.2.intermediate.dense.bias', 'encoder.layer.22.ffn.2.intermediate.dense.weight', 'encoder.layer.22.ffn.2.output.LayerNorm.bias', 'encoder.layer.22.ffn.2.output.LayerNorm.weight', 'encoder.layer.22.ffn.2.output.dense.bias', 'encoder.layer.22.ffn.2.output.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.22.output.bottleneck.LayerNorm.bias', 'encoder.layer.22.output.bottleneck.LayerNorm.weight', 'encoder.layer.22.output.bottleneck.dense.bias', 'encoder.layer.22.output.bottleneck.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.23.bottleneck.attention.LayerNorm.bias', 'encoder.layer.23.bottleneck.attention.LayerNorm.weight', 'encoder.layer.23.bottleneck.attention.dense.bias', 'encoder.layer.23.bottleneck.attention.dense.weight', 'encoder.layer.23.bottleneck.input.LayerNorm.bias', 'encoder.layer.23.bottleneck.input.LayerNorm.weight', 'encoder.layer.23.bottleneck.input.dense.bias', 'encoder.layer.23.bottleneck.input.dense.weight', 'encoder.layer.23.ffn.0.intermediate.dense.bias', 'encoder.layer.23.ffn.0.intermediate.dense.weight', 'encoder.layer.23.ffn.0.output.LayerNorm.bias', 'encoder.layer.23.ffn.0.output.LayerNorm.weight', 'encoder.layer.23.ffn.0.output.dense.bias', 'encoder.layer.23.ffn.0.output.dense.weight', 'encoder.layer.23.ffn.1.intermediate.dense.bias', 'encoder.layer.23.ffn.1.intermediate.dense.weight', 'encoder.layer.23.ffn.1.output.LayerNorm.bias', 'encoder.layer.23.ffn.1.output.LayerNorm.weight', 'encoder.layer.23.ffn.1.output.dense.bias', 'encoder.layer.23.ffn.1.output.dense.weight', 'encoder.layer.23.ffn.2.intermediate.dense.bias', 'encoder.layer.23.ffn.2.intermediate.dense.weight', 'encoder.layer.23.ffn.2.output.LayerNorm.bias', 'encoder.layer.23.ffn.2.output.LayerNorm.weight', 'encoder.layer.23.ffn.2.output.dense.bias', 'encoder.layer.23.ffn.2.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.23.output.bottleneck.LayerNorm.bias', 'encoder.layer.23.output.bottleneck.LayerNorm.weight', 'encoder.layer.23.output.bottleneck.dense.bias', 'encoder.layer.23.output.bottleneck.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.bottleneck.attention.LayerNorm.bias', 'encoder.layer.3.bottleneck.attention.LayerNorm.weight', 'encoder.layer.3.bottleneck.attention.dense.bias', 'encoder.layer.3.bottleneck.attention.dense.weight', 'encoder.layer.3.bottleneck.input.LayerNorm.bias', 'encoder.layer.3.bottleneck.input.LayerNorm.weight', 'encoder.layer.3.bottleneck.input.dense.bias', 'encoder.layer.3.bottleneck.input.dense.weight', 'encoder.layer.3.ffn.0.intermediate.dense.bias', 'encoder.layer.3.ffn.0.intermediate.dense.weight', 'encoder.layer.3.ffn.0.output.LayerNorm.bias', 'encoder.layer.3.ffn.0.output.LayerNorm.weight', 'encoder.layer.3.ffn.0.output.dense.bias', 'encoder.layer.3.ffn.0.output.dense.weight', 'encoder.layer.3.ffn.1.intermediate.dense.bias', 'encoder.layer.3.ffn.1.intermediate.dense.weight', 'encoder.layer.3.ffn.1.output.LayerNorm.bias', 'encoder.layer.3.ffn.1.output.LayerNorm.weight', 'encoder.layer.3.ffn.1.output.dense.bias', 'encoder.layer.3.ffn.1.output.dense.weight', 'encoder.layer.3.ffn.2.intermediate.dense.bias', 'encoder.layer.3.ffn.2.intermediate.dense.weight', 'encoder.layer.3.ffn.2.output.LayerNorm.bias', 'encoder.layer.3.ffn.2.output.LayerNorm.weight', 'encoder.layer.3.ffn.2.output.dense.bias', 'encoder.layer.3.ffn.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.bottleneck.LayerNorm.bias', 'encoder.layer.3.output.bottleneck.LayerNorm.weight', 'encoder.layer.3.output.bottleneck.dense.bias', 'encoder.layer.3.output.bottleneck.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.bottleneck.attention.LayerNorm.bias', 'encoder.layer.4.bottleneck.attention.LayerNorm.weight', 'encoder.layer.4.bottleneck.attention.dense.bias', 'encoder.layer.4.bottleneck.attention.dense.weight', 'encoder.layer.4.bottleneck.input.LayerNorm.bias', 'encoder.layer.4.bottleneck.input.LayerNorm.weight', 'encoder.layer.4.bottleneck.input.dense.bias', 'encoder.layer.4.bottleneck.input.dense.weight', 'encoder.layer.4.ffn.0.intermediate.dense.bias', 'encoder.layer.4.ffn.0.intermediate.dense.weight', 'encoder.layer.4.ffn.0.output.LayerNorm.bias', 'encoder.layer.4.ffn.0.output.LayerNorm.weight', 'encoder.layer.4.ffn.0.output.dense.bias', 'encoder.layer.4.ffn.0.output.dense.weight', 'encoder.layer.4.ffn.1.intermediate.dense.bias', 'encoder.layer.4.ffn.1.intermediate.dense.weight', 'encoder.layer.4.ffn.1.output.LayerNorm.bias', 'encoder.layer.4.ffn.1.output.LayerNorm.weight', 'encoder.layer.4.ffn.1.output.dense.bias', 'encoder.layer.4.ffn.1.output.dense.weight', 'encoder.layer.4.ffn.2.intermediate.dense.bias', 'encoder.layer.4.ffn.2.intermediate.dense.weight', 'encoder.layer.4.ffn.2.output.LayerNorm.bias', 'encoder.layer.4.ffn.2.output.LayerNorm.weight', 'encoder.layer.4.ffn.2.output.dense.bias', 'encoder.layer.4.ffn.2.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.bottleneck.LayerNorm.bias', 'encoder.layer.4.output.bottleneck.LayerNorm.weight', 'encoder.layer.4.output.bottleneck.dense.bias', 'encoder.layer.4.output.bottleneck.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.bottleneck.attention.LayerNorm.bias', 'encoder.layer.5.bottleneck.attention.LayerNorm.weight', 'encoder.layer.5.bottleneck.attention.dense.bias', 'encoder.layer.5.bottleneck.attention.dense.weight', 'encoder.layer.5.bottleneck.input.LayerNorm.bias', 'encoder.layer.5.bottleneck.input.LayerNorm.weight', 'encoder.layer.5.bottleneck.input.dense.bias', 'encoder.layer.5.bottleneck.input.dense.weight', 'encoder.layer.5.ffn.0.intermediate.dense.bias', 'encoder.layer.5.ffn.0.intermediate.dense.weight', 'encoder.layer.5.ffn.0.output.LayerNorm.bias', 'encoder.layer.5.ffn.0.output.LayerNorm.weight', 'encoder.layer.5.ffn.0.output.dense.bias', 'encoder.layer.5.ffn.0.output.dense.weight', 'encoder.layer.5.ffn.1.intermediate.dense.bias', 'encoder.layer.5.ffn.1.intermediate.dense.weight', 'encoder.layer.5.ffn.1.output.LayerNorm.bias', 'encoder.layer.5.ffn.1.output.LayerNorm.weight', 'encoder.layer.5.ffn.1.output.dense.bias', 'encoder.layer.5.ffn.1.output.dense.weight', 'encoder.layer.5.ffn.2.intermediate.dense.bias', 'encoder.layer.5.ffn.2.intermediate.dense.weight', 'encoder.layer.5.ffn.2.output.LayerNorm.bias', 'encoder.layer.5.ffn.2.output.LayerNorm.weight', 'encoder.layer.5.ffn.2.output.dense.bias', 'encoder.layer.5.ffn.2.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.bottleneck.LayerNorm.bias', 'encoder.layer.5.output.bottleneck.LayerNorm.weight', 'encoder.layer.5.output.bottleneck.dense.bias', 'encoder.layer.5.output.bottleneck.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.bottleneck.attention.LayerNorm.bias', 'encoder.layer.6.bottleneck.attention.LayerNorm.weight', 'encoder.layer.6.bottleneck.attention.dense.bias', 'encoder.layer.6.bottleneck.attention.dense.weight', 'encoder.layer.6.bottleneck.input.LayerNorm.bias', 'encoder.layer.6.bottleneck.input.LayerNorm.weight', 'encoder.layer.6.bottleneck.input.dense.bias', 'encoder.layer.6.bottleneck.input.dense.weight', 'encoder.layer.6.ffn.0.intermediate.dense.bias', 'encoder.layer.6.ffn.0.intermediate.dense.weight', 'encoder.layer.6.ffn.0.output.LayerNorm.bias', 'encoder.layer.6.ffn.0.output.LayerNorm.weight', 'encoder.layer.6.ffn.0.output.dense.bias', 'encoder.layer.6.ffn.0.output.dense.weight', 'encoder.layer.6.ffn.1.intermediate.dense.bias', 'encoder.layer.6.ffn.1.intermediate.dense.weight', 'encoder.layer.6.ffn.1.output.LayerNorm.bias', 'encoder.layer.6.ffn.1.output.LayerNorm.weight', 'encoder.layer.6.ffn.1.output.dense.bias', 'encoder.layer.6.ffn.1.output.dense.weight', 'encoder.layer.6.ffn.2.intermediate.dense.bias', 'encoder.layer.6.ffn.2.intermediate.dense.weight', 'encoder.layer.6.ffn.2.output.LayerNorm.bias', 'encoder.layer.6.ffn.2.output.LayerNorm.weight', 'encoder.layer.6.ffn.2.output.dense.bias', 'encoder.layer.6.ffn.2.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.bottleneck.LayerNorm.bias', 'encoder.layer.6.output.bottleneck.LayerNorm.weight', 'encoder.layer.6.output.bottleneck.dense.bias', 'encoder.layer.6.output.bottleneck.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.bottleneck.attention.LayerNorm.bias', 'encoder.layer.7.bottleneck.attention.LayerNorm.weight', 'encoder.layer.7.bottleneck.attention.dense.bias', 'encoder.layer.7.bottleneck.attention.dense.weight', 'encoder.layer.7.bottleneck.input.LayerNorm.bias', 'encoder.layer.7.bottleneck.input.LayerNorm.weight', 'encoder.layer.7.bottleneck.input.dense.bias', 'encoder.layer.7.bottleneck.input.dense.weight', 'encoder.layer.7.ffn.0.intermediate.dense.bias', 'encoder.layer.7.ffn.0.intermediate.dense.weight', 'encoder.layer.7.ffn.0.output.LayerNorm.bias', 'encoder.layer.7.ffn.0.output.LayerNorm.weight', 'encoder.layer.7.ffn.0.output.dense.bias', 'encoder.layer.7.ffn.0.output.dense.weight', 'encoder.layer.7.ffn.1.intermediate.dense.bias', 'encoder.layer.7.ffn.1.intermediate.dense.weight', 'encoder.layer.7.ffn.1.output.LayerNorm.bias', 'encoder.layer.7.ffn.1.output.LayerNorm.weight', 'encoder.layer.7.ffn.1.output.dense.bias', 'encoder.layer.7.ffn.1.output.dense.weight', 'encoder.layer.7.ffn.2.intermediate.dense.bias', 'encoder.layer.7.ffn.2.intermediate.dense.weight', 'encoder.layer.7.ffn.2.output.LayerNorm.bias', 'encoder.layer.7.ffn.2.output.LayerNorm.weight', 'encoder.layer.7.ffn.2.output.dense.bias', 'encoder.layer.7.ffn.2.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.bottleneck.LayerNorm.bias', 'encoder.layer.7.output.bottleneck.LayerNorm.weight', 'encoder.layer.7.output.bottleneck.dense.bias', 'encoder.layer.7.output.bottleneck.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.bottleneck.attention.LayerNorm.bias', 'encoder.layer.8.bottleneck.attention.LayerNorm.weight', 'encoder.layer.8.bottleneck.attention.dense.bias', 'encoder.layer.8.bottleneck.attention.dense.weight', 'encoder.layer.8.bottleneck.input.LayerNorm.bias', 'encoder.layer.8.bottleneck.input.LayerNorm.weight', 'encoder.layer.8.bottleneck.input.dense.bias', 'encoder.layer.8.bottleneck.input.dense.weight', 'encoder.layer.8.ffn.0.intermediate.dense.bias', 'encoder.layer.8.ffn.0.intermediate.dense.weight', 'encoder.layer.8.ffn.0.output.LayerNorm.bias', 'encoder.layer.8.ffn.0.output.LayerNorm.weight', 'encoder.layer.8.ffn.0.output.dense.bias', 'encoder.layer.8.ffn.0.output.dense.weight', 'encoder.layer.8.ffn.1.intermediate.dense.bias', 'encoder.layer.8.ffn.1.intermediate.dense.weight', 'encoder.layer.8.ffn.1.output.LayerNorm.bias', 'encoder.layer.8.ffn.1.output.LayerNorm.weight', 'encoder.layer.8.ffn.1.output.dense.bias', 'encoder.layer.8.ffn.1.output.dense.weight', 'encoder.layer.8.ffn.2.intermediate.dense.bias', 'encoder.layer.8.ffn.2.intermediate.dense.weight', 'encoder.layer.8.ffn.2.output.LayerNorm.bias', 'encoder.layer.8.ffn.2.output.LayerNorm.weight', 'encoder.layer.8.ffn.2.output.dense.bias', 'encoder.layer.8.ffn.2.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.bottleneck.LayerNorm.bias', 'encoder.layer.8.output.bottleneck.LayerNorm.weight', 'encoder.layer.8.output.bottleneck.dense.bias', 'encoder.layer.8.output.bottleneck.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.bottleneck.attention.LayerNorm.bias', 'encoder.layer.9.bottleneck.attention.LayerNorm.weight', 'encoder.layer.9.bottleneck.attention.dense.bias', 'encoder.layer.9.bottleneck.attention.dense.weight', 'encoder.layer.9.bottleneck.input.LayerNorm.bias', 'encoder.layer.9.bottleneck.input.LayerNorm.weight', 'encoder.layer.9.bottleneck.input.dense.bias', 'encoder.layer.9.bottleneck.input.dense.weight', 'encoder.layer.9.ffn.0.intermediate.dense.bias', 'encoder.layer.9.ffn.0.intermediate.dense.weight', 'encoder.layer.9.ffn.0.output.LayerNorm.bias', 'encoder.layer.9.ffn.0.output.LayerNorm.weight', 'encoder.layer.9.ffn.0.output.dense.bias', 'encoder.layer.9.ffn.0.output.dense.weight', 'encoder.layer.9.ffn.1.intermediate.dense.bias', 'encoder.layer.9.ffn.1.intermediate.dense.weight', 'encoder.layer.9.ffn.1.output.LayerNorm.bias', 'encoder.layer.9.ffn.1.output.LayerNorm.weight', 'encoder.layer.9.ffn.1.output.dense.bias', 'encoder.layer.9.ffn.1.output.dense.weight', 'encoder.layer.9.ffn.2.intermediate.dense.bias', 'encoder.layer.9.ffn.2.intermediate.dense.weight', 'encoder.layer.9.ffn.2.output.LayerNorm.bias', 'encoder.layer.9.ffn.2.output.LayerNorm.weight', 'encoder.layer.9.ffn.2.output.dense.bias', 'encoder.layer.9.ffn.2.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.bottleneck.LayerNorm.bias', 'encoder.layer.9.output.bottleneck.LayerNorm.weight', 'encoder.layer.9.output.bottleneck.dense.bias', 'encoder.layer.9.output.bottleneck.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='640' max='5682' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 640/5682 02:25 < 19:10, 4.38 it/s, Epoch 0.11/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>0.693757</td>\n",
       "      <td>0.501760</td>\n",
       "      <td>0.668229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.694200</td>\n",
       "      <td>0.693411</td>\n",
       "      <td>0.498240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.692800</td>\n",
       "      <td>0.693166</td>\n",
       "      <td>0.501760</td>\n",
       "      <td>0.668229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.693300</td>\n",
       "      <td>0.693056</td>\n",
       "      <td>0.501760</td>\n",
       "      <td>0.668229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>0.693325</td>\n",
       "      <td>0.501760</td>\n",
       "      <td>0.668229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.688300</td>\n",
       "      <td>0.695088</td>\n",
       "      <td>0.501760</td>\n",
       "      <td>0.668229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/onyxia/Hackathon-AI-vs-IA/mobilebert.ipynb Cell 12\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://user-assil-92139-0.user.lab.sspcloud.fr/home/onyxia/Hackathon-AI-vs-IA/mobilebert.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://user-assil-92139-0.user.lab.sspcloud.fr/home/onyxia/Hackathon-AI-vs-IA/mobilebert.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell://user-assil-92139-0.user.lab.sspcloud.fr/home/onyxia/Hackathon-AI-vs-IA/mobilebert.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://user-assil-92139-0.user.lab.sspcloud.fr/home/onyxia/Hackathon-AI-vs-IA/mobilebert.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics\n\u001b[1;32m     <a href='vscode-notebook-cell://user-assil-92139-0.user.lab.sspcloud.fr/home/onyxia/Hackathon-AI-vs-IA/mobilebert.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://user-assil-92139-0.user.lab.sspcloud.fr/home/onyxia/Hackathon-AI-vs-IA/mobilebert.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://user-assil-92139-0.user.lab.sspcloud.fr/home/onyxia/Hackathon-AI-vs-IA/mobilebert.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://user-assil-92139-0.user.lab.sspcloud.fr/home/onyxia/Hackathon-AI-vs-IA/mobilebert.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# Save the trained model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://user-assil-92139-0.user.lab.sspcloud.fr/home/onyxia/Hackathon-AI-vs-IA/mobilebert.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m'\u001b[39m\u001b[39mmodel_mobilebert.pth\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1860\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1861\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1862\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1863\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1864\u001b[0m     )\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/transformers/trainer.py:2203\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   2202\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2203\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   2205\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2206\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2207\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2208\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2209\u001b[0m ):\n\u001b[1;32m   2210\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2211\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/transformers/trainer.py:3138\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3135\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   3137\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3138\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   3140\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3141\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/transformers/trainer.py:3161\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3159\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3160\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 3161\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   3162\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3163\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:1284\u001b[0m, in \u001b[0;36mMobileBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1278\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1284\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmobilebert(\n\u001b[1;32m   1285\u001b[0m     input_ids,\n\u001b[1;32m   1286\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1287\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1288\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1289\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1290\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1291\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1292\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1293\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1294\u001b[0m )\n\u001b[1;32m   1296\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1298\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:898\u001b[0m, in \u001b[0;36mMobileBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_hidden_states, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    893\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    895\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    896\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids, position_ids\u001b[39m=\u001b[39mposition_ids, token_type_ids\u001b[39m=\u001b[39mtoken_type_ids, inputs_embeds\u001b[39m=\u001b[39minputs_embeds\n\u001b[1;32m    897\u001b[0m )\n\u001b[0;32m--> 898\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    899\u001b[0m     embedding_output,\n\u001b[1;32m    900\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    901\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    902\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    903\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    904\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    905\u001b[0m )\n\u001b[1;32m    906\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    907\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:583\u001b[0m, in \u001b[0;36mMobileBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    581\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 583\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    584\u001b[0m     hidden_states,\n\u001b[1;32m    585\u001b[0m     attention_mask,\n\u001b[1;32m    586\u001b[0m     head_mask[i],\n\u001b[1;32m    587\u001b[0m     output_attentions,\n\u001b[1;32m    588\u001b[0m )\n\u001b[1;32m    589\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:526\u001b[0m, in \u001b[0;36mMobileBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     query_tensor, key_tensor, value_tensor, layer_input \u001b[39m=\u001b[39m [hidden_states] \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m--> 526\u001b[0m self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    527\u001b[0m     query_tensor,\n\u001b[1;32m    528\u001b[0m     key_tensor,\n\u001b[1;32m    529\u001b[0m     value_tensor,\n\u001b[1;32m    530\u001b[0m     layer_input,\n\u001b[1;32m    531\u001b[0m     attention_mask,\n\u001b[1;32m    532\u001b[0m     head_mask,\n\u001b[1;32m    533\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    534\u001b[0m )\n\u001b[1;32m    535\u001b[0m attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    536\u001b[0m s \u001b[39m=\u001b[39m (attention_output,)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:360\u001b[0m, in \u001b[0;36mMobileBertAttention.forward\u001b[0;34m(self, query_tensor, key_tensor, value_tensor, layer_input, attention_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    351\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    352\u001b[0m     query_tensor: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    358\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    359\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 360\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    361\u001b[0m         query_tensor,\n\u001b[1;32m    362\u001b[0m         key_tensor,\n\u001b[1;32m    363\u001b[0m         value_tensor,\n\u001b[1;32m    364\u001b[0m         attention_mask,\n\u001b[1;32m    365\u001b[0m         head_mask,\n\u001b[1;32m    366\u001b[0m         output_attentions,\n\u001b[1;32m    367\u001b[0m     )\n\u001b[1;32m    368\u001b[0m     \u001b[39m# Run a linear projection of `hidden_size` then add a residual\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     \u001b[39m# with `layer_input`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], layer_input)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/transformers/models/mobilebert/modeling_mobilebert.py:302\u001b[0m, in \u001b[0;36mMobileBertSelfAttention.forward\u001b[0;34m(self, query_tensor, key_tensor, value_tensor, attention_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    300\u001b[0m context_layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(attention_probs, value_layer)\n\u001b[1;32m    301\u001b[0m context_layer \u001b[39m=\u001b[39m context_layer\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m--> 302\u001b[0m new_context_layer_shape \u001b[39m=\u001b[39m context_layer\u001b[39m.\u001b[39;49msize()[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_head_size,)\n\u001b[1;32m    303\u001b[0m context_layer \u001b[39m=\u001b[39m context_layer\u001b[39m.\u001b[39mview(new_context_layer_shape)\n\u001b[1;32m    304\u001b[0m outputs \u001b[39m=\u001b[39m (context_layer, attention_probs) \u001b[39mif\u001b[39;00m output_attentions \u001b[39melse\u001b[39;00m (context_layer,)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import MobileBertTokenizer, MobileBertForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "import torch.cuda\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "# Split the dataset\n",
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "test_val_dataset = train_test_split['test']\n",
    "\n",
    "test_val_split = test_val_dataset.train_test_split(test_size=0.5, seed=42)\n",
    "eval_dataset = test_val_split['train']\n",
    "test_dataset = test_val_split['test']\n",
    "\n",
    "# Load the model\n",
    "model = MobileBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "print(model.device)\n",
    "\n",
    "# Check for GPU availability and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(model.device)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100\n",
    ")\n",
    "\n",
    "# Define the metrics function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='binary')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1_score': f1,\n",
    "    }\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'model_mobilebert.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.91939457937346\n",
      "Test F1 Score: 0.9186500888099467\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Move the model to the appropriate device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Evaluate the model on the test dataset\n",
    "predictions = trainer.predict(test_dataset)\n",
    "test_metrics = compute_metrics(predictions)\n",
    "print(\"Test Accuracy:\", test_metrics['accuracy'])\n",
    "print(\"Test F1 Score:\", test_metrics['f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 0\n",
      "Probabilities: [0.9990405440330505, 0.000959432334639132]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Check for GPU availability and set the device accordingly\n",
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cuda\")\n",
    "model.to(device)  # Move the model to the appropriate device\n",
    "\n",
    "# Function to make a prediction on a single sentence\n",
    "def predict(sentence):\n",
    "    # Tokenize the sentence so it matches the format expected by the model\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():  # Disable gradient calculation to speed up the process and reduce memory usage\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    # Apply softmax to logits to get probabilities\n",
    "    probabilities = softmax(logits, dim=1)\n",
    "\n",
    "    # Assuming we have two classes, 0 and 1, and class 0 is the 'negative' class\n",
    "    prediction = probabilities.argmax().item()  # Get the index of the highest probability\n",
    "    return {\"class\": prediction, \"probabilities\": probabilities.tolist()[0]}\n",
    "\n",
    "# Example usage\n",
    "user_sentence = \"Yes, it is possible to be subject to a cash withdrawal even if you do not use an ATM. There are several ways that this could happen:Debit card transactions: If you make a purchase using your debit card, the merchant may automatically withdraw the amount of the purchase from your checking account. This is essentially the same as making a cash withdrawal.Bank fees: Some banks charge fees for maintaining an account or for using certain services. These fees may be automatically withdrawn from your account on a regular basis.Automatic payments: If you have set up automatic payments for bills or other expenses, the amount of the payment will be withdrawn from your account when it is due.Check payments: If you write a check to pay for something, the recipient may deposit the check and withdraw the funds from your account.Electronic transfers: You may also be subject to a cash withdrawal if you authorize an electronic transfer of funds from your account to another account.In summary, there are many ways that you could be subject to a cash withdrawal even if you do not use an ATM. It is important to carefully track your account balance and be aware of any automatic transactions or payments that may be taking place.\"\n",
    "result = predict(user_sentence)\n",
    "print(\"Predicted Class:\", result[\"class\"])\n",
    "print(\"Probabilities:\", result[\"probabilities\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
